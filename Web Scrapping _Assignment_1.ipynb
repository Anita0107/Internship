{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a73636a7",
   "metadata": {},
   "source": [
    "1. Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41fa0514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\anaconda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2020.12.5)\n",
      "h1 -> Main Page\n",
      "h2 -> From today's featured article\n",
      "h2 -> Did you know ...\n",
      "h2 -> In the news\n",
      "h2 -> On this day\n",
      "h2 -> From today's featured list\n",
      "h2 -> Today's featured picture\n",
      "h2 -> Other areas of Wikipedia\n",
      "h2 -> Wikipedia's sister projects\n",
      "h2 -> Wikipedia languages\n",
      "h2 -> Navigation menu\n",
      "h3 -> Personal tools\n",
      "h3 -> Namespaces\n",
      "h3 -> Variants\n",
      "expanded\n",
      "collapsed\n",
      "h3 -> Views\n",
      "h3 -> More\n",
      "expanded\n",
      "collapsed\n",
      "h3 -> Search\n",
      "h3 -> Navigation\n",
      "h3 -> Contribute\n",
      "h3 -> Tools\n",
      "h3 -> Print/export\n",
      "h3 -> In other projects\n",
      "h3 -> Languages\n"
     ]
    }
   ],
   "source": [
    "#Sol 1: \n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "url = 'https://en.wikipedia.org/wiki/Main_Page'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "header_tags= [\"h1\",\"h2\",\"h3\"]\n",
    "for i in soup.findAll(header_tags):\n",
    "    print(i.name + ' -> ' + i.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73028069",
   "metadata": {},
   "source": [
    "2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80279b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\anaconda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests) (4.0.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of movie</th>\n",
       "      <th>Year of Release</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soorarai Pottru</td>\n",
       "      <td>2020</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Incendies</td>\n",
       "      <td>2010</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Dune: Part One</td>\n",
       "      <td>2021</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Kimetsu no Yaiba: Mugen Ressha-Hen</td>\n",
       "      <td>2020</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>The Father</td>\n",
       "      <td>I 2020</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Inglourious Basterds</td>\n",
       "      <td>2009</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name of movie Year of Release Ratings\n",
       "0             The Shawshank Redemption            1994     9.3\n",
       "1                        The Godfather            1972     9.2\n",
       "2                      Soorarai Pottru            2020     9.1\n",
       "3                      The Dark Knight            2008     9.0\n",
       "4               The Godfather: Part II            1974     9.0\n",
       "..                                 ...             ...     ...\n",
       "95                           Incendies            2010     8.3\n",
       "96                      Dune: Part One            2021     8.3\n",
       "97  Kimetsu no Yaiba: Mugen Ressha-Hen            2020     8.3\n",
       "98                          The Father          I 2020     8.3\n",
       "99                Inglourious Basterds            2009     8.3\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sol 2.\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "url = 'https://www.imdb.com/search/title/?count=100&groups=top_1000&sort=user_rating'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "movie_name = []\n",
    "year_of_release = []\n",
    "rating = []\n",
    "\n",
    "movie_data = soup.findAll('div',{'class' : 'lister-item mode-advanced'})\n",
    "\n",
    "for store in movie_data:\n",
    "    name = store.h3.a.text\n",
    "    movie_name.append(name)\n",
    "    \n",
    "    year = store.h3.find('span', class_ = 'lister-item-year text-muted unbold').text.replace('(', '').replace(')', '')\n",
    "    year_of_release.append(year)\n",
    "    \n",
    "    rate = store.find('div', class_ = 'inline-block ratings-imdb-rating').text.replace('\\n', '')\n",
    "    rating.append(rate)\n",
    "    \n",
    "    \n",
    "movies_dF = pd.DataFrame({'Name of movie' : movie_name, \"Year of Release\" : year_of_release, \"Ratings\" : rating})\n",
    "movies_dF   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7593256a",
   "metadata": {},
   "source": [
    "3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2d2d8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\anaconda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of movie</th>\n",
       "      <th>Year of Release</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Udaan</td>\n",
       "      <td>2010</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gangs of Wasseypur</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taare Zameen Par</td>\n",
       "      <td>2007</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dev.D</td>\n",
       "      <td>2009</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Swades: We, the People</td>\n",
       "      <td>2004</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Baby</td>\n",
       "      <td>I 2015</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Deewaar</td>\n",
       "      <td>1975</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Khosla Ka Ghosla!</td>\n",
       "      <td>2006</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Iqbal</td>\n",
       "      <td>2005</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Muqaddar Ka Sikandar</td>\n",
       "      <td>1978</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name of movie Year of Release Ratings\n",
       "0                    Udaan            2010     8.2\n",
       "1       Gangs of Wasseypur            2012     8.2\n",
       "2         Taare Zameen Par            2007     8.4\n",
       "3                    Dev.D            2009       8\n",
       "4   Swades: We, the People            2004     8.2\n",
       "..                     ...             ...     ...\n",
       "95                    Baby          I 2015       8\n",
       "96                 Deewaar            1975     8.1\n",
       "97       Khosla Ka Ghosla!            2006     8.3\n",
       "98                   Iqbal            2005     8.1\n",
       "99    Muqaddar Ka Sikandar            1978     7.5\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sol 3.\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "url = \"https://www.imdb.com/list/ls004221468/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "movie_name = []\n",
    "year_of_release = []\n",
    "rating = []\n",
    "movie_data = soup.findAll('div',{'class' : 'lister-item mode-detail'})\n",
    "\n",
    "for store in movie_data:\n",
    "    name = store.h3.a.text\n",
    "    movie_name.append(name)\n",
    "    \n",
    "    year = store.h3.find('span', class_ = 'lister-item-year text-muted unbold').text.replace('(', '').replace(')', '')\n",
    "    year_of_release.append(year)\n",
    "    \n",
    "    rate = store.find('div', class_ = 'ipl-rating-star small').text.replace('\\n', '')\n",
    "    rating.append(rate)\n",
    "    \n",
    "movie_dF = pd.DataFrame({'Name of movie' : movie_name, \"Year of Release\" : year_of_release, \"Ratings\" : rating})\n",
    "movie_dF  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40dc400",
   "metadata": {},
   "source": [
    "4. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "iii) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc2e8fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\anaconda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.4)\n",
      "  Team Position Team Nationality Team Matches Team Points Team Rating\n",
      "0             1      New Zealand           17       2,054         121\n",
      "1             2          England           32       3,793         119\n",
      "2             3        Australia           28       3,244         116\n",
      "3             4            India           32       3,624         113\n",
      "4             5     South Africa           25       2,459          98\n",
      "5             6         Pakistan           27       2,524          93\n",
      "6             7       Bangladesh           30       2,740          91\n",
      "7             8      West Indies           30       2,523          84\n",
      "8             9        Sri Lanka           32       2,657          83\n",
      "9            10      Afghanistan           17       1,054          62\n"
     ]
    }
   ],
   "source": [
    "# Sol 4.\n",
    "# i)\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from requests import get\n",
    "\n",
    "#main_code_line2\n",
    "\n",
    "from requests import get\n",
    "\n",
    "url=get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "\n",
    "team_ranking=[]\n",
    "team_name=[]\n",
    "team_match=[]\n",
    "team_point=[]\n",
    "team_rating=[]\n",
    "\n",
    "request=url.text\n",
    "\n",
    "soup_data=Soup(request,'html.parser')\n",
    "\n",
    "ranking=soup_data.find_all('tr',class_='rankings-block__banner')\n",
    "\n",
    "for rank in ranking:\n",
    "    team=rank.find('td',{'class':'rankings-block__banner--pos'}).text\n",
    "    team_ranking.append(team)\n",
    "    \n",
    "    team=rank.find('span',{'class':'u-hide-phablet'}).text\n",
    "    team_name.append(team)\n",
    "    \n",
    "    team=rank.find('td',{'class':'rankings-block__banner--matches'}).text\n",
    "    team_match.append(team)\n",
    "    \n",
    "    team=rank.find('td',{'class':'rankings-block__banner--points'}).text\n",
    "    team_point.append(team)\n",
    "    \n",
    "    team=rank.find('td',{'class':'rankings-block__banner--rating u-text-right'}).text.strip()\n",
    "    team_rating.append(team)\n",
    "\n",
    "rankings=soup_data.find_all('tr',class_='table-body')\n",
    "count=0\n",
    "for rank in rankings:\n",
    "    count=count+1\n",
    "    team=rank.find('td',{'class':'table-body__cell table-body__cell--position u-text-right'}).text\n",
    "    team_ranking.append(team)\n",
    "    \n",
    "    team=rank.find('span',{'class':'u-hide-phablet'}).text\n",
    "    team_name.append(team)\n",
    "    \n",
    "    team=rank.find('td',{'class':'table-body__cell u-text-right rating'}).text\n",
    "    team_rating.append(team)\n",
    "    if count>8:\n",
    "        break\n",
    "    \n",
    "matchpoint=soup_data.find_all('td',class_='table-body__cell u-center-text')\n",
    "count=1\n",
    "\n",
    "for point in matchpoint:\n",
    "    if count%2!=0:\n",
    "        team_match.append(matchpoint[count-1].text)\n",
    "    else:\n",
    "        team_point.append(matchpoint[count-1].text)\n",
    "    count=count+1\n",
    "    if count>18:\n",
    "        break\n",
    "        \n",
    "for team_info in range(10):\n",
    "       cric_dF = pd.DataFrame({'Team Position' :team_ranking,'Team Nationality':team_name,'Team Matches':team_match,'Team Points': team_point,'Team Rating':team_rating})\n",
    "print(cric_dF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7481128d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\anaconda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests) (4.0.0)\n",
      "  Player Position      Player Name Player Nation Player Rating\n",
      "0               1       Babar Azam           PAK           873\n",
      "1               2      Virat Kohli           IND           844\n",
      "2               3     Rohit Sharma           IND           813\n",
      "3               4      Ross Taylor            NZ           801\n",
      "4               5      Aaron Finch           AUS           779\n",
      "5               6   Jonny Bairstow           ENG           775\n",
      "6               7     David Warner           AUS           762\n",
      "7               8        Shai Hope            WI           758\n",
      "8               9  Kane Williamson            NZ           754\n",
      "9              10  Quinton de Kock            SA           747\n"
     ]
    }
   ],
   "source": [
    "# ii)\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from requests import get\n",
    "\n",
    "url=get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\")\n",
    "\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "\n",
    "request=url.text\n",
    "\n",
    "soup_data=Soup(request,'html.parser')\n",
    "\n",
    "player_pos=[]\n",
    "player_name=[]\n",
    "player_nation=[]\n",
    "player_rating=[]\n",
    "\n",
    "info=soup_data.find_all('tr',attrs={'class':'rankings-block__banner'})\n",
    "\n",
    "for infor in info:\n",
    "    information=infor.find('td',class_='rankings-block__position').text\n",
    "    player_pos.append(information)\n",
    "    \n",
    "    information=infor.find('div',class_='rankings-block__banner--name-large').text\n",
    "    player_name.append(information)\n",
    "    \n",
    "    information=infor.find(class_='flag-15')\n",
    "    player_nation.append(str(information).split('\"')[1].split()[1])\n",
    "    \n",
    "    information=infor.find(class_='rankings-block__banner--rating').text\n",
    "    player_rating.append(information)\n",
    "\n",
    "infos=soup_data.find_all('tr',attrs={'class':'table-body'})\n",
    "\n",
    "count=0\n",
    "\n",
    "for infor in infos:\n",
    "    count=count+1\n",
    "    information=infor.find('td',class_='table-body__cell table-body__cell--position u-text-right').text.strip()\n",
    "    player_pos.append(information)\n",
    "    \n",
    "    information=infor.find('td',class_='table-body__cell rankings-table__name name').text.strip()\n",
    "    player_name.append(information)\n",
    "    \n",
    "    information=infor.find('span',class_='table-body__logo-text').text\n",
    "    player_nation.append(information)\n",
    "    \n",
    "    information=infor.find('td',class_='table-body__cell rating').text\n",
    "    player_rating.append(information)\n",
    "    if count>8:\n",
    "        break\n",
    "\n",
    "for team_info in range(10):\n",
    "        movie_dF = pd.DataFrame({'Player Position' :player_pos,'Player Name':player_name,'Player Nation':player_nation,'Player Rating':player_rating})\n",
    "print(movie_dF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "605ce20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\anaconda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests) (4.0.0)\n",
      "  Player Position       Player Name Player Nation Player Rating\n",
      "0               1       Trent Boult            NZ           737\n",
      "1               2    Josh Hazlewood           AUS           709\n",
      "2               3  Mujeeb Ur Rahman           AFG           708\n",
      "3               4      Chris Woakes           ENG           700\n",
      "4               5      Mehedi Hasan           BAN           692\n",
      "5               6        Matt Henry            NZ           691\n",
      "6               7    Jasprit Bumrah           IND           679\n",
      "7               8    Mitchell Starc           AUS           652\n",
      "8               9   Shakib Al Hasan           BAN           650\n",
      "9              10     Kagiso Rabada            SA           646\n"
     ]
    }
   ],
   "source": [
    "# iii)\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "from requests import get\n",
    "\n",
    "url=get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")\n",
    "\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "\n",
    "request=url.text\n",
    "\n",
    "soup_data=Soup(request,'html.parser')\n",
    "\n",
    "player_pos=[]\n",
    "player_name=[]\n",
    "player_nation=[]\n",
    "player_rating=[]\n",
    "\n",
    "info=soup_data.find_all('tr',attrs={'class':'rankings-block__banner'})\n",
    "\n",
    "for infor in info:\n",
    "    information=infor.find('td',class_='rankings-block__position').text\n",
    "    player_pos.append(information)\n",
    "    \n",
    "    information=infor.find('div',class_='rankings-block__banner--name-large').text\n",
    "    player_name.append(information)\n",
    "    \n",
    "    information=infor.find(class_='flag-15')\n",
    "    player_nation.append(str(information).split('\"')[1].split()[1])\n",
    "    \n",
    "    information=infor.find(class_='rankings-block__banner--rating').text\n",
    "    player_rating.append(information)\n",
    "\n",
    "infos=soup_data.find_all('tr',attrs={'class':'table-body'})\n",
    "\n",
    "count=0\n",
    "\n",
    "for infor in infos:\n",
    "    count=count+1\n",
    "    information=infor.find('td',class_='table-body__cell table-body__cell--position u-text-right').text.strip()\n",
    "    player_pos.append(information)\n",
    "    \n",
    "    information=infor.find('td',class_='table-body__cell rankings-table__name name').text.strip()\n",
    "    player_name.append(information)\n",
    "    \n",
    "    information=infor.find('span',class_='table-body__logo-text').text\n",
    "    player_nation.append(information)\n",
    "    \n",
    "    information=infor.find('td',class_='table-body__cell rating').text\n",
    "    player_rating.append(information)\n",
    "    if count>8:\n",
    "        break\n",
    "\n",
    "for team_info in range(10):\n",
    "        cric_dF = pd.DataFrame({'Player Position' :player_pos,'Player Name':player_name,'Player Nation':player_nation,'Player Rating':player_rating})\n",
    "print(cric_dF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21009236",
   "metadata": {},
   "source": [
    "5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "ii) Top 10 women’s ODI players along with the records of their team and rating.\n",
    "iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f20d9f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\anaconda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2020.12.5)\n",
      "  Team Position Team Nationality Team Matches Team Points Team Rating\n",
      "0             1        Australia           21       3,379         161\n",
      "1             2          England           25       2,983         119\n",
      "2             3     South Africa           29       3,390         117\n",
      "3             4            India           26       2,934         113\n",
      "4             5      New Zealand           26       2,392          92\n",
      "5             6      West Indies           22       1,872          85\n",
      "6             7         Pakistan           20       1,496          75\n",
      "7             8       Bangladesh            5         306          61\n",
      "8             9        Sri Lanka           11         519          47\n",
      "9            10          Ireland            2          25          13\n"
     ]
    }
   ],
   "source": [
    "# Sol 5.\n",
    "# i)\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "url=get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "team_ranking=[]\n",
    "team_name=[]\n",
    "team_match=[]\n",
    "team_point=[]\n",
    "team_rating=[]\n",
    "\n",
    "request=url.text\n",
    "\n",
    "soup_data=Soup(request,'html.parser')\n",
    "\n",
    "ranking=soup_data.find_all('tr',class_='rankings-block__banner')\n",
    "\n",
    "for rank in ranking:\n",
    "    team=rank.find('td',{'class':'rankings-block__banner--pos'}).text\n",
    "    team_ranking.append(team)\n",
    "    \n",
    "    team=rank.find('span',{'class':'u-hide-phablet'}).text\n",
    "    team_name.append(team)\n",
    "    \n",
    "    team=rank.find('td',{'class':'rankings-block__banner--matches'}).text\n",
    "    team_match.append(team)\n",
    "    \n",
    "    team=rank.find('td',{'class':'rankings-block__banner--points'}).text\n",
    "    team_point.append(team)\n",
    "    \n",
    "    team=rank.find('td',{'class':'rankings-block__banner--rating u-text-right'}).text.strip()\n",
    "    team_rating.append(team)\n",
    "\n",
    "rankings=soup_data.find_all('tr',class_='table-body')\n",
    "\n",
    "for rank in rankings:\n",
    "    team=rank.find('td',{'class':'table-body__cell table-body__cell--position u-text-right'}).text\n",
    "    team_ranking.append(team)\n",
    "    \n",
    "    team=rank.find('span',{'class':'u-hide-phablet'}).text\n",
    "    team_name.append(team)\n",
    "    \n",
    "    team=rank.find('td',{'class':'table-body__cell u-text-right rating'}).text\n",
    "    team_rating.append(team)\n",
    "    \n",
    "matchpoint=soup_data.find_all('td',class_='table-body__cell u-center-text')\n",
    "count=1\n",
    "for point in matchpoint:\n",
    "    if count%2!=0:\n",
    "        team_match.append(matchpoint[count-1].text)\n",
    "    else:\n",
    "        team_point.append(matchpoint[count-1].text)\n",
    "    count=count+1\n",
    "    if count>20:\n",
    "        break\n",
    "        \n",
    "for team_info in range(10):\n",
    "        cric_dF = pd.DataFrame({'Team Position' :team_ranking,'Team Nationality':team_name,'Team Matches':team_match,'Team Points':team_point,'Team Rating':team_rating})\n",
    "print(cric_dF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a82702d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\anaconda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests) (4.0.0)\n",
      "  Player Position        Player Name Player Nationality Player Rating\n",
      "0               1      Jess Jonassen                AUS           760\n",
      "1               2     Jhulan Goswami                IND           727\n",
      "2               3       Megan Schutt                AUS           717\n",
      "3               4     Marizanne Kapp                 SA           715\n",
      "4               5  Sophie Ecclestone                ENG           701\n",
      "5               6     Shabnim Ismail                 SA           688\n",
      "6               7    Katherine Brunt                ENG           666\n",
      "7               8     Ayabonga Khaka                 SA           643\n",
      "8               9     Anya Shrubsole                ENG           598\n",
      "9              10         Kate Cross                ENG           589\n"
     ]
    }
   ],
   "source": [
    "# ii)\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from requests import get\n",
    "\n",
    "url=get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling\")\n",
    "\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "\n",
    "request=url.text\n",
    "\n",
    "soup_data=Soup(request,'html.parser')\n",
    "\n",
    "player_pos=[]\n",
    "player_name=[]\n",
    "player_nation=[]\n",
    "player_rating=[]\n",
    "\n",
    "info=soup_data.find_all('tr',attrs={'class':'rankings-block__banner'})\n",
    "\n",
    "for infor in info:\n",
    "    information=infor.find('td',class_='rankings-block__position').text\n",
    "    player_pos.append(information)\n",
    "    \n",
    "    information=infor.find('div',class_='rankings-block__banner--name-large').text\n",
    "    player_name.append(information)\n",
    "    \n",
    "    information=infor.find(class_='flag-15')\n",
    "    player_nation.append(str(information).split('\"')[1].split()[1])\n",
    "    \n",
    "    information=infor.find(class_='rankings-block__banner--rating').text\n",
    "    player_rating.append(information)\n",
    "\n",
    "infos=soup_data.find_all('tr',attrs={'class':'table-body'})\n",
    "\n",
    "count=0\n",
    "\n",
    "for infor in infos:\n",
    "    count=count+1\n",
    "    information=infor.find('td',class_='table-body__cell table-body__cell--position u-text-right').text.strip()\n",
    "    player_pos.append(information)\n",
    "    \n",
    "    information=infor.find('td',class_='table-body__cell rankings-table__name name').text.strip()\n",
    "    player_name.append(information)\n",
    "    \n",
    "    information=infor.find('span',class_='table-body__logo-text').text\n",
    "    player_nation.append(information)\n",
    "    \n",
    "    information=infor.find('td',class_='table-body__cell rating').text\n",
    "    player_rating.append(information)\n",
    "    if count>8:\n",
    "        break\n",
    "\n",
    "for team_info in range(10):\n",
    "        cric_dF = pd.DataFrame({'Player Position' :player_pos,'Player Name':player_name,'Player Nationality':player_nation,'Player Rating':player_rating})\n",
    "print(cric_dF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2710d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\anaconda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (2.10)\n",
      "  Player Position       Player Name Player Nationality Player Rating\n",
      "0               1    Marizanne Kapp                 SA           384\n",
      "1               2    Natalie Sciver                ENG           372\n",
      "2               3      Ellyse Perry                AUS           365\n",
      "3               4   Stafanie Taylor                 WI           322\n",
      "4               5     Deepti Sharma                IND           299\n",
      "5               6  Ashleigh Gardner                AUS           275\n",
      "6               7  Dane van Niekerk                 SA           274\n",
      "7               8     Jess Jonassen                AUS           272\n",
      "8                   Katherine Brunt                ENG           272\n",
      "9              10    Jhulan Goswami                IND           251\n"
     ]
    }
   ],
   "source": [
    "# iii)\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from requests import get\n",
    "\n",
    "url=get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")\n",
    "\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "\n",
    "request=url.text\n",
    "\n",
    "soup_data=Soup(request,'html.parser')\n",
    "\n",
    "player_pos=[]\n",
    "player_name=[]\n",
    "player_nation=[]\n",
    "player_rating=[]\n",
    "\n",
    "info=soup_data.find_all('tr',attrs={'class':'rankings-block__banner'})\n",
    "\n",
    "for infor in info:\n",
    "    information=infor.find('td',class_='rankings-block__position').text\n",
    "    player_pos.append(information)\n",
    "    \n",
    "    information=infor.find('div',class_='rankings-block__banner--name-large').text\n",
    "    player_name.append(information)\n",
    "    \n",
    "    information=infor.find(class_='flag-15')\n",
    "    player_nation.append(str(information).split('\"')[1].split()[1])\n",
    "    \n",
    "    information=infor.find(class_='rankings-block__banner--rating').text\n",
    "    player_rating.append(information)\n",
    "\n",
    "infos=soup_data.find_all('tr',attrs={'class':'table-body'})\n",
    "\n",
    "count=0\n",
    "\n",
    "for infor in infos:\n",
    "    count=count+1\n",
    "    information=infor.find('td',class_='table-body__cell table-body__cell--position u-text-right').text.strip()\n",
    "    player_pos.append(information)\n",
    "    \n",
    "    information=infor.find('td',class_='table-body__cell rankings-table__name name').text.strip()\n",
    "    player_name.append(information)\n",
    "    \n",
    "    information=infor.find('span',class_='table-body__logo-text').text\n",
    "    player_nation.append(information)\n",
    "    \n",
    "    information=infor.find('td',class_='table-body__cell rating').text\n",
    "    player_rating.append(information)\n",
    "    if count>8:\n",
    "        break\n",
    "\n",
    "for team_info in range(10):\n",
    "        cric_dF = pd.DataFrame({'Player Position' :player_pos,'Player Name':player_name,'Player Nationality':player_nation,'Player Rating':player_rating})\n",
    "print(cric_dF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed5b618",
   "metadata": {},
   "source": [
    "6. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fbc814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\anaconda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2020.12.5)\n",
      "<Response [503]>\n"
     ]
    }
   ],
   "source": [
    "# Sol 6. Due to 503 error the data cant be scraped\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "url = 'https://www.amazon.in/Phone-Under-20000/s?k=Phone+Under+20000'\n",
    "response = requests.get(url)\n",
    "print(response)\n",
    "soup = BeautifulSoup(response.content,'html.parser') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a29be44",
   "metadata": {},
   "source": [
    "7. Write a python program to scrape house details from mentioned url. It should include house title, location, area, emi and price\n",
    "\"https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44N DUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8 iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be50b9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\anaconda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2020.12.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>House Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Area</th>\n",
       "      <th>EMI</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Hebba...</td>\n",
       "      <td>[ Bangalore - Hosur Road,  Near  National Publ...</td>\n",
       "      <td>1,800 sqft</td>\n",
       "      <td>₹77,374/Month</td>\n",
       "      <td>₹1.35 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 BHK Apartment  For Sale  In Nisarga Residenc...</td>\n",
       "      <td>[ Ananth Nagar,  Electronic City Phase II,  Ba...</td>\n",
       "      <td>2,000 sqft</td>\n",
       "      <td>₹45,851/Month</td>\n",
       "      <td>₹80 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 BHK Flat  For Sale  In Sobha Silicon Oasis  ...</td>\n",
       "      <td>[ Rayasandra Bengaluru,  Karnataka 560100 Indi...</td>\n",
       "      <td>1,879 sqft</td>\n",
       "      <td>₹9,170/Month</td>\n",
       "      <td>₹16 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 BHK For Sale  In Daadys Garden In Electronic...</td>\n",
       "      <td>[ Kammasandra,  Electronic City,  Bengaluru,  ...</td>\n",
       "      <td>2,600 sqft</td>\n",
       "      <td>₹85,971/Month</td>\n",
       "      <td>₹1.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 BHK Flat  For Sale  In</td>\n",
       "      <td>[ Electronic City Standalone Building,  16th C...</td>\n",
       "      <td>2,000 sqft</td>\n",
       "      <td>₹39,546/Month</td>\n",
       "      <td>₹69 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4 BHK Flat  For Sale  In Hosa Road</td>\n",
       "      <td>[ Parappana Agrahara Standalone Building,  11t...</td>\n",
       "      <td>3,000 sqft</td>\n",
       "      <td>₹71,643/Month</td>\n",
       "      <td>₹1.25 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Elect...</td>\n",
       "      <td>[ surya nagar face 1Explore Nearby2021-08-264 ...</td>\n",
       "      <td>3,000 sqft</td>\n",
       "      <td>₹1.43 Lacs/Month</td>\n",
       "      <td>₹2.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Elect...</td>\n",
       "      <td>[ Hosur Rd, Near Infosys LimitedExplore Nearby...</td>\n",
       "      <td>1,200 sqft</td>\n",
       "      <td>₹42,985/Month</td>\n",
       "      <td>₹75 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4 BHK Apartment  For Sale  In Gopalan Gardenia...</td>\n",
       "      <td>[ Veerasandra Main Rd,  Veer Sandra,  Electron...</td>\n",
       "      <td>2,650 sqft</td>\n",
       "      <td>₹68,777/Month</td>\n",
       "      <td>₹1.2 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4 BHK For Sale  In Gpr Royale In Gpr Royale 6t...</td>\n",
       "      <td>[]</td>\n",
       "      <td>3,100 sqft</td>\n",
       "      <td>₹85,971/Month</td>\n",
       "      <td>₹1.5 Crores</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          House Name  \\\n",
       "0  4 BHK In Independent House  For Sale  In Hebba...   \n",
       "1  4 BHK Apartment  For Sale  In Nisarga Residenc...   \n",
       "2  4 BHK Flat  For Sale  In Sobha Silicon Oasis  ...   \n",
       "3  4 BHK For Sale  In Daadys Garden In Electronic...   \n",
       "4                          4 BHK Flat  For Sale  In    \n",
       "5                 4 BHK Flat  For Sale  In Hosa Road   \n",
       "6  4 BHK In Independent House  For Sale  In Elect...   \n",
       "7  4 BHK In Independent House  For Sale  In Elect...   \n",
       "8  4 BHK Apartment  For Sale  In Gopalan Gardenia...   \n",
       "9  4 BHK For Sale  In Gpr Royale In Gpr Royale 6t...   \n",
       "\n",
       "                                            Location        Area  \\\n",
       "0  [ Bangalore - Hosur Road,  Near  National Publ...  1,800 sqft   \n",
       "1  [ Ananth Nagar,  Electronic City Phase II,  Ba...  2,000 sqft   \n",
       "2  [ Rayasandra Bengaluru,  Karnataka 560100 Indi...  1,879 sqft   \n",
       "3  [ Kammasandra,  Electronic City,  Bengaluru,  ...  2,600 sqft   \n",
       "4  [ Electronic City Standalone Building,  16th C...  2,000 sqft   \n",
       "5  [ Parappana Agrahara Standalone Building,  11t...  3,000 sqft   \n",
       "6  [ surya nagar face 1Explore Nearby2021-08-264 ...  3,000 sqft   \n",
       "7  [ Hosur Rd, Near Infosys LimitedExplore Nearby...  1,200 sqft   \n",
       "8  [ Veerasandra Main Rd,  Veer Sandra,  Electron...  2,650 sqft   \n",
       "9                                                 []  3,100 sqft   \n",
       "\n",
       "                EMI         Price  \n",
       "0     ₹77,374/Month  ₹1.35 Crores  \n",
       "1     ₹45,851/Month      ₹80 Lacs  \n",
       "2      ₹9,170/Month      ₹16 Lacs  \n",
       "3     ₹85,971/Month   ₹1.5 Crores  \n",
       "4     ₹39,546/Month      ₹69 Lacs  \n",
       "5     ₹71,643/Month  ₹1.25 Crores  \n",
       "6  ₹1.43 Lacs/Month   ₹2.5 Crores  \n",
       "7     ₹42,985/Month      ₹75 Lacs  \n",
       "8     ₹68,777/Month   ₹1.2 Crores  \n",
       "9     ₹85,971/Month   ₹1.5 Crores  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sol 7.\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "url = 'https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44N DUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8 iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser') \n",
    "broker_info = soup.find_all ('div', {'class' : 'nb__2JHKO'})\n",
    "\n",
    "house_name=[]\n",
    "for i in broker_info:\n",
    "    restro = i.find('section', class_ ='nb__37AJO').text.split(',')[0]\n",
    "    house_name.append(restro)\n",
    "    \n",
    "location=[]\n",
    "for j in broker_info:\n",
    "    loc = j.find('div', class_ ='nb__sDz3z').text.split(',')[1:]\n",
    "    location.append(loc)\n",
    "    \n",
    "info= soup.find_all('div',class_='nb__2NPHR')    \n",
    "informations=[]    \n",
    "area=[]\n",
    "emi=[]\n",
    "price=[]\n",
    "\n",
    "for infor in info:\n",
    "    information=infor.find('div')\n",
    "    if information != None:\n",
    "        informations.append(information.text)\n",
    "for fill in range(0,3):\n",
    "    count=fill\n",
    "    for filling in range(10):\n",
    "        if fill==0:\n",
    "            area.append(informations[count])\n",
    "        if fill==1:\n",
    "            emi.append(informations[count])\n",
    "        if fill==2:\n",
    "            price.append(informations[count])\n",
    "        count=count+3\n",
    "\n",
    "house_dF = pd.DataFrame({'House Name' : house_name, \"Location\" : location, \"Area\" : area, \"EMI\" : emi , \"Price\" : price })\n",
    "house_dF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb79ae",
   "metadata": {},
   "source": [
    "8. Write a python program to scrape mentioned details from ‘https://www.dineout.co.in/delhi-restaurants/buffet-special’ :\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c48dbf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\anaconda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2020.12.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>3.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree3CS Mall</td>\n",
       "      <td>North Indian, Barbecue, Italian, Asian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle BarbequePacific Mall</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria</td>\n",
       "      <td>Barbecue, Chinese, Mughlai, North Indian</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel</td>\n",
       "      <td>Multi-Cuisine, North Indian, Italian, Contine...</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India GrillHilton Garden Inn</td>\n",
       "      <td>North Indian, Italian, Oriental</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico</td>\n",
       "      <td>Barbecue, North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "      <td>North Indian, Chinese, Fast Food</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World CafeVibe by The Lalit Traveller</td>\n",
       "      <td>North Indian, Chinese, Continental</td>\n",
       "      <td>Vibe by The Lalit Traveller,Sector 35, Faridabad</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill RoomSuncity Business Tower</td>\n",
       "      <td>North Indian, Mughlai, Barbecue</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mad 4 Bar B QueSector 29</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Sector 29, Faridabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barbeque 29NIT</td>\n",
       "      <td>North Indian, Chinese, Barbecue</td>\n",
       "      <td>NIT, Faridabad</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GlasshouseDoubleTree By Hilton Gurugram Baani ...</td>\n",
       "      <td>Multi-Cuisine, Asian, European, Italian, Nort...</td>\n",
       "      <td>DoubleTree By Hilton Gurugram Baani Square,Sec...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Restaurant Name  \\\n",
       "0                      Castle BarbequeConnaught Place   \n",
       "1                             Jungle Jamboree3CS Mall   \n",
       "2                         Castle BarbequePacific Mall   \n",
       "3                The Barbeque CompanyGardens Galleria   \n",
       "4       Cafe KnoshThe Leela Ambience Convention Hotel   \n",
       "5                        India GrillHilton Garden Inn   \n",
       "6                Delhi BarbequeTaurus Sarovar Portico   \n",
       "7   The Monarch - Bar Be Que VillageIndirapuram Ha...   \n",
       "8               World CafeVibe by The Lalit Traveller   \n",
       "9             Indian Grill RoomSuncity Business Tower   \n",
       "10                           Mad 4 Bar B QueSector 29   \n",
       "11                                     Barbeque 29NIT   \n",
       "12  GlasshouseDoubleTree By Hilton Gurugram Baani ...   \n",
       "\n",
       "                                              Cuisine  \\\n",
       "0                               Chinese, North Indian   \n",
       "1              North Indian, Barbecue, Italian, Asian   \n",
       "2                               North Indian, Chinese   \n",
       "3            Barbecue, Chinese, Mughlai, North Indian   \n",
       "4    Multi-Cuisine, North Indian, Italian, Contine...   \n",
       "5                    North Indian, Italian, Oriental    \n",
       "6                              Barbecue, North Indian   \n",
       "7                    North Indian, Chinese, Fast Food   \n",
       "8                  North Indian, Chinese, Continental   \n",
       "9                     North Indian, Mughlai, Barbecue   \n",
       "10                              North Indian, Mughlai   \n",
       "11                    North Indian, Chinese, Barbecue   \n",
       "12   Multi-Cuisine, Asian, European, Italian, Nort...   \n",
       "\n",
       "                                             Location Ratings  \\\n",
       "0                      Connaught Place, Central Delhi     3.4   \n",
       "1              3CS Mall,Lajpat Nagar - 3, South Delhi     3.9   \n",
       "2              Pacific Mall,Tagore Garden, West Delhi       4   \n",
       "3                  Gardens Galleria,Sector 38A, Noida     4.1   \n",
       "4   The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "5                Hilton Garden Inn,Saket, South Delhi     3.9   \n",
       "6      Taurus Sarovar Portico,Mahipalpur, South Delhi     3.6   \n",
       "7   Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.9   \n",
       "8    Vibe by The Lalit Traveller,Sector 35, Faridabad     4.3   \n",
       "9    Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "10                               Sector 29, Faridabad     3.8   \n",
       "11                                     NIT, Faridabad     4.2   \n",
       "12  DoubleTree By Hilton Gurugram Baani Square,Sec...       4   \n",
       "\n",
       "                                            Image URL  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sol 8.\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "url = 'https://www.dineout.co.in/delhi-restaurants/buffet-special'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "restaurant_info = soup.find_all ('div', {'class' : 'restnt-card restaurant'})\n",
    "\n",
    "#i) \n",
    "restro_name = []  \n",
    "for stuny in restaurant_info:\n",
    "    restro = stuny.find('div', class_ ='restnt-info cursor').text.split(',')[0]\n",
    "    restro_name.append(restro)\n",
    "\n",
    "#ii)\n",
    "cuisine = []  \n",
    "for stuny in restaurant_info:\n",
    "    cuisine_n = stuny.find('span', class_ ='double-line-ellipsis').text.split('|')[1]\n",
    "    cuisine.append(cuisine_n)\n",
    "\n",
    "#iii)\n",
    "locations = []  \n",
    "for stuny in restaurant_info:\n",
    "    locs_data = stuny.find('div', class_ ='restnt-loc ellipsis').text    \n",
    "    locations.append(locs_data)   \n",
    "\n",
    "#iv)\n",
    "ratings = []  \n",
    "for stuny in restaurant_info:\n",
    "    ratings_data = stuny.find('div', class_ ='img-wrap').text    \n",
    "    ratings.append(ratings_data)\n",
    "    \n",
    "#v)\n",
    "Image_url = []  \n",
    "for stuny in restaurant_info:\n",
    "    img_data = stuny.find('img', class_ ='no-img')\n",
    "    Image_url.append(img_data['data-src']) \n",
    "\n",
    "restro_dF = pd.DataFrame({'Restaurant Name' : restro_name, \"Cuisine\" : cuisine, \"Location\" : locations, \"Ratings\" : ratings , \"Image URL\" : Image_url})\n",
    "restro_dF "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3f43e",
   "metadata": {},
   "source": [
    "9. Write a python program to scrape weather details for last 24 hours from ‘https://en.tutiempo.net/delhi.html?data=last-24- hours’ :\n",
    "i) Hour\n",
    "ii) Temperature\n",
    "iii) Wind\n",
    "iv) Weather condition\n",
    "v) Humidity\n",
    "vi) Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34c61a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\anaconda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests) (4.0.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Weather Condition</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:30</td>\n",
       "      <td>20°C</td>\n",
       "      <td>7 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>64%</td>\n",
       "      <td>1015 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00</td>\n",
       "      <td>20°C</td>\n",
       "      <td>7 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>64%</td>\n",
       "      <td>1015 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23:30</td>\n",
       "      <td>20°C</td>\n",
       "      <td>9 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>64%</td>\n",
       "      <td>1015 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23:00</td>\n",
       "      <td>20°C</td>\n",
       "      <td>7 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>64%</td>\n",
       "      <td>1015 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22:30</td>\n",
       "      <td>21°C</td>\n",
       "      <td>11 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>60%</td>\n",
       "      <td>1015 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22:00</td>\n",
       "      <td>21°C</td>\n",
       "      <td>11 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>60%</td>\n",
       "      <td>1015 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21:30</td>\n",
       "      <td>21°C</td>\n",
       "      <td>9 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>60%</td>\n",
       "      <td>1015 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21:00</td>\n",
       "      <td>21°C</td>\n",
       "      <td>9 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>60%</td>\n",
       "      <td>1014 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20:30</td>\n",
       "      <td>22°C</td>\n",
       "      <td>9 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>57%</td>\n",
       "      <td>1014 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20:00</td>\n",
       "      <td>22°C</td>\n",
       "      <td>9 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>57%</td>\n",
       "      <td>1014 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19:30</td>\n",
       "      <td>22°C</td>\n",
       "      <td>7 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>53%</td>\n",
       "      <td>1014 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19:00</td>\n",
       "      <td>23°C</td>\n",
       "      <td>7 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>50%</td>\n",
       "      <td>1013 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18:30</td>\n",
       "      <td>24°C</td>\n",
       "      <td>7 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>44%</td>\n",
       "      <td>1013 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18:00</td>\n",
       "      <td>25°C</td>\n",
       "      <td>7 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>41%</td>\n",
       "      <td>1013 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17:30</td>\n",
       "      <td>27°C</td>\n",
       "      <td>7 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>34%</td>\n",
       "      <td>1012 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17:00</td>\n",
       "      <td>27°C</td>\n",
       "      <td>7 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>34%</td>\n",
       "      <td>1012 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16:30</td>\n",
       "      <td>28°C</td>\n",
       "      <td>7 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>32%</td>\n",
       "      <td>1012 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16:00</td>\n",
       "      <td>28°C</td>\n",
       "      <td>9 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>28%</td>\n",
       "      <td>1012 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15:30</td>\n",
       "      <td>29°C</td>\n",
       "      <td>9 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>23%</td>\n",
       "      <td>1012 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15:00</td>\n",
       "      <td>29°C</td>\n",
       "      <td>9 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>22%</td>\n",
       "      <td>1013 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14:30</td>\n",
       "      <td>29°C</td>\n",
       "      <td>9 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>22%</td>\n",
       "      <td>1013 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14:00</td>\n",
       "      <td>29°C</td>\n",
       "      <td>11 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>23%</td>\n",
       "      <td>1013 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>13:30</td>\n",
       "      <td>28°C</td>\n",
       "      <td>11 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>28%</td>\n",
       "      <td>1014 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13:00</td>\n",
       "      <td>28°C</td>\n",
       "      <td>6 km/h</td>\n",
       "      <td>Mist</td>\n",
       "      <td>28%</td>\n",
       "      <td>1014 hPa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Hour Temperature     Wind Weather Condition Humidity  Pressure\n",
       "0   00:30        20°C   7 km/h              Mist      64%  1015 hPa\n",
       "1   00:00        20°C   7 km/h              Mist      64%  1015 hPa\n",
       "2   23:30        20°C   9 km/h              Mist      64%  1015 hPa\n",
       "3   23:00        20°C   7 km/h              Mist      64%  1015 hPa\n",
       "4   22:30        21°C  11 km/h              Mist      60%  1015 hPa\n",
       "5   22:00        21°C  11 km/h              Mist      60%  1015 hPa\n",
       "6   21:30        21°C   9 km/h              Mist      60%  1015 hPa\n",
       "7   21:00        21°C   9 km/h              Mist      60%  1014 hPa\n",
       "8   20:30        22°C   9 km/h              Mist      57%  1014 hPa\n",
       "9   20:00        22°C   9 km/h              Mist      57%  1014 hPa\n",
       "10  19:30        22°C   7 km/h              Mist      53%  1014 hPa\n",
       "11  19:00        23°C   7 km/h              Mist      50%  1013 hPa\n",
       "12  18:30        24°C   7 km/h              Mist      44%  1013 hPa\n",
       "13  18:00        25°C   7 km/h              Mist      41%  1013 hPa\n",
       "14  17:30        27°C   7 km/h              Mist      34%  1012 hPa\n",
       "15  17:00        27°C   7 km/h              Mist      34%  1012 hPa\n",
       "16  16:30        28°C   7 km/h              Mist      32%  1012 hPa\n",
       "17  16:00        28°C   9 km/h              Mist      28%  1012 hPa\n",
       "18  15:30        29°C   9 km/h              Mist      23%  1012 hPa\n",
       "19  15:00        29°C   9 km/h              Mist      22%  1013 hPa\n",
       "20  14:30        29°C   9 km/h              Mist      22%  1013 hPa\n",
       "21  14:00        29°C  11 km/h              Mist      23%  1013 hPa\n",
       "22  13:30        28°C  11 km/h              Mist      28%  1014 hPa\n",
       "23  13:00        28°C   6 km/h              Mist      28%  1014 hPa"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sol 9.\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "url = \"https://en.tutiempo.net/delhi.html?data=last-24-hours\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "hour=[]\n",
    "for i in soup.find_all('td',class_='t Temp')[0:24]:\n",
    "    if i.previous_sibling.previous_sibling is not None:\n",
    "          hour.append(i.previous_sibling.previous_sibling.text)\n",
    "    else:\n",
    "        Hour.append(' ')\n",
    "temp=[]\n",
    "for j in soup.find_all('td',class_='t Temp')[0:24]:\n",
    "    tempt=j.text\n",
    "    temp.append(tempt)\n",
    "\n",
    "wind=[]\n",
    "for k in soup.find_all('td',class_='wind')[0:24]:\n",
    "    w=k.text\n",
    "    wind.append(w)\n",
    "    \n",
    "weather_cond=[]\n",
    "for l in soup.find_all('span',class_='thhip ico i0530 u303n')[0:24]:\n",
    "    x=l.text\n",
    "    weather_cond.append(x)\n",
    "        \n",
    "humidity=[]\n",
    "for n in soup.find_all('td',class_='hr')[0:24]:\n",
    "    y=n.text\n",
    "    humidity.append(y)\n",
    "    \n",
    "pressure =[]\n",
    "for p in soup.find_all('td',class_='prob')[0:24]:\n",
    "    ze= p.text\n",
    "    pressure.append(ze)\n",
    "\n",
    "climate_dF=pd.DataFrame({'Hour' : hour, 'Temperature' : temp, 'Wind' : wind, 'Weather Condition' : weather_cond , 'Humidity' : humidity, 'Pressure' : pressure})\n",
    "climate_dF "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98acd168",
   "metadata": {},
   "source": [
    "10. Write a python program to scrape monument name, monument description, image url about top 10 monuments from 'https://www.puredestinations.co.uk/top-10-famous-monuments-to-visit-in-india/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd4c3a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in d:\\anaconda\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests) (4.0.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Monument Name</th>\n",
       "      <th>Monument Description</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taj Mahal, Agra</td>\n",
       "      <td>Enlisted in the Seven Wonders of the World, Th...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Golden Temple (Harmandir Sahib), Amritsar</td>\n",
       "      <td>The holiest shrine and pilgrimage place locate...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meenakshi Temple, Madurai</td>\n",
       "      <td>Meenakshi Temple is situated on the Southern b...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mysore Palace, Mysore</td>\n",
       "      <td>The Mysore Palace is a famous historical monum...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gateway of India, Mumbai</td>\n",
       "      <td>Even though Mumbai is famous for its Bollywood...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Red Fort, New Delhi</td>\n",
       "      <td>Declared as the UNESCO’s World Heritage Site, ...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hawa Mahal, Jaipur</td>\n",
       "      <td>Explore a blend of beauty and Rajasthan cultur...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Qutub Minar, New Delhi</td>\n",
       "      <td>Discover one of the tallest towers in the worl...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sanchi Stupa, Sanchi</td>\n",
       "      <td>The beautiful and massive dome, Sanchi Stupa a...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Charminar, Hyderabad</td>\n",
       "      <td>No visit to Hyderabad should be complete witho...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Monument Name  \\\n",
       "0                             Taj Mahal, Agra   \n",
       "1  Golden Temple (Harmandir Sahib), Amritsar    \n",
       "2                   Meenakshi Temple, Madurai   \n",
       "3                       Mysore Palace, Mysore   \n",
       "4                    Gateway of India, Mumbai   \n",
       "5                         Red Fort, New Delhi   \n",
       "6                          Hawa Mahal, Jaipur   \n",
       "7                      Qutub Minar, New Delhi   \n",
       "8                        Sanchi Stupa, Sanchi   \n",
       "9                        Charminar, Hyderabad   \n",
       "\n",
       "                                Monument Description  \\\n",
       "0  Enlisted in the Seven Wonders of the World, Th...   \n",
       "1  The holiest shrine and pilgrimage place locate...   \n",
       "2  Meenakshi Temple is situated on the Southern b...   \n",
       "3  The Mysore Palace is a famous historical monum...   \n",
       "4  Even though Mumbai is famous for its Bollywood...   \n",
       "5  Declared as the UNESCO’s World Heritage Site, ...   \n",
       "6  Explore a blend of beauty and Rajasthan cultur...   \n",
       "7  Discover one of the tallest towers in the worl...   \n",
       "8  The beautiful and massive dome, Sanchi Stupa a...   \n",
       "9  No visit to Hyderabad should be complete witho...   \n",
       "\n",
       "                                           Image URL  \n",
       "0  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "1  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "2  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "3  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "4  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "5  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "6  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "7  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "8  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "9  http://www.puredestinations.co.uk/wp-content/u...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sol 10.\n",
    "\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "url = \"https://www.puredestinations.co.uk/top-10-famous-monuments-to-visit-in-india/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "table= soup.find_all('div', class_ ='blog--single__content column--3-4 u-spacing-third')\n",
    "place=[]\n",
    "for i in table:\n",
    "    for j in i.find_all('p'):\n",
    "        t= j.text.replace('\\n','')\n",
    "        place.append(t)\n",
    "        \n",
    "name= []\n",
    "desc = []\n",
    "for i in range(1,30,3):\n",
    "    name.append(place[i])\n",
    "for i in range(2,30,3):\n",
    "    desc.append(place[i])\n",
    "\n",
    "temp =[]\n",
    "for t in soup.find_all('img'):\n",
    "    temp.append(t['src'])\n",
    "img_url=[]\n",
    "for t in range(6,26,2):\n",
    "    img_url.append(temp[t])\n",
    "    \n",
    "monument_dF = pd.DataFrame({'Monument Name' : name, \"Monument Description\" : desc, \"Image URL\" : img_url})\n",
    "monument_dF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf07f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
