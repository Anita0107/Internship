{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb427bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a79f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73636a7",
   "metadata": {},
   "source": [
    "1. Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sol 1: \n",
    "url = 'https://en.wikipedia.org/wiki/Main_Page'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "header_tags= [\"h1\",\"h2\",\"h3\"]\n",
    "for i in soup.findAll(header_tags):\n",
    "    print(i.name + ' -> ' + i.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73028069",
   "metadata": {},
   "source": [
    "2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80279b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sol 2.\n",
    "url = 'https://www.imdb.com/search/title/?count=100&groups=top_1000&sort=user_rating'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "movie_name = []\n",
    "year_of_release = []\n",
    "rating = []\n",
    "\n",
    "movie_data = soup.findAll('div',{'class' : 'lister-item mode-advanced'})\n",
    "\n",
    "for store in movie_data:\n",
    "    name = store.h3.a.text\n",
    "    movie_name.append(name)\n",
    "    \n",
    "    year = store.h3.find('span', class_ = 'lister-item-year text-muted unbold').text.replace('(', '').replace(')', '')\n",
    "    year_of_release.append(year)\n",
    "    \n",
    "    rate = store.find('div', class_ = 'inline-block ratings-imdb-rating').text.replace('\\n', '')\n",
    "    rating.append(rate)\n",
    "    \n",
    "    \n",
    "movies_dF = pd.DataFrame({'Name of movie' : movie_name, \"Year of Release\" : year_of_release, \"Ratings\" : rating})\n",
    "movies_dF   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7593256a",
   "metadata": {},
   "source": [
    "3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d2d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sol 3.\n",
    "url = \"https://www.imdb.com/list/ls004221468/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "movie_name = []\n",
    "year_of_release = []\n",
    "rating = []\n",
    "movie_data = soup.findAll('div',{'class' : 'lister-item mode-detail'})\n",
    "\n",
    "for store in movie_data:\n",
    "    name = store.h3.a.text\n",
    "    movie_name.append(name)\n",
    "    \n",
    "    year = store.h3.find('span', class_ = 'lister-item-year text-muted unbold').text.replace('(', '').replace(')', '')\n",
    "    year_of_release.append(year)\n",
    "    \n",
    "    rate = store.find('div', class_ = 'ipl-rating-star small').text.replace('\\n', '')\n",
    "    rating.append(rate)\n",
    "    \n",
    "movie_dF = pd.DataFrame({'Name of movie' : movie_name, \"Year of Release\" : year_of_release, \"Ratings\" : rating})\n",
    "movie_dF  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40dc400",
   "metadata": {},
   "source": [
    "4. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "iii) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e8fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sol 4.\n",
    "# a)\n",
    "from requests import get\n",
    "\n",
    "url=get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "\n",
    "\n",
    "\n",
    "team_ranking=[]\n",
    "team_name=[]\n",
    "team_match=[]\n",
    "team_point=[]\n",
    "team_rating=[]\n",
    "\n",
    "request=url.text\n",
    "\n",
    "soup_data=soup(request,'html.parser')\n",
    "\n",
    "ranking=soup_data.find_all('tr',class_='rankings-block__banner')\n",
    "\n",
    "for rank in ranking:\n",
    "    team=rank.find('td',{'class':'rankings-block__banner--pos'}).text\n",
    "    team_ranking.append(team)\n",
    "    \n",
    "    team=rank.find('span',{'class':'u-hide-phablet'}).text\n",
    "    team_name.append(team)\n",
    "    \n",
    "    team=rank.find('td',{'class':'rankings-block__banner--matches'}).text\n",
    "    team_match.append(team)\n",
    "    team=rank.find('td',{'class':'rankings-block__banner--points'}).text\n",
    "    team_point.append(team)\n",
    "    \n",
    "    team=rank.find('td',{'class':'rankings-block__banner--rating u-text-right'}).text.strip()\n",
    "    team_rating.append(team)\n",
    "\n",
    "rankings=soup_data.find_all('tr',class_='table-body')\n",
    "\n",
    "for rank in rankings:\n",
    "    team=rank.find('td',{'class':'table-body__cell table-body__cell--position u-text-right'}).text\n",
    "    team_ranking.append(team)\n",
    "    \n",
    "    team=rank.find('span',{'class':'u-hide-phablet'}).text\n",
    "    team_name.append(team)\n",
    "    \n",
    "    team=rank.find('td',{'class':'table-body__cell u-text-right rating'}).text\n",
    "    team_rating.append(team)\n",
    "    \n",
    "matchpoint=soup_data.find_all('td',class_='table-body__cell u-center-text')\n",
    "count=1\n",
    "\n",
    "for point in matchpoint:\n",
    "    if count%2!=0:\n",
    "        team_match.append(matchpoint[count-1].text)\n",
    "    else:\n",
    "        team_point.append(matchpoint[count-1].text)\n",
    "    count=count+1\n",
    "    if count>20:\n",
    "        break\n",
    "        \n",
    "\n",
    "for team_info in range(10):\n",
    "    print('Team Position :',team_ranking[team_info],'\\nTeam Nationality :',team_name[team_info],'\\nTeam Matches :',team_match[team_info],'\\nTeam Points :',team_point[team_info],'\\nTeam Rating :',team_rating[team_info],'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7481128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b)\n",
    "from requests import get\n",
    "url=get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\")\n",
    "request=url.text\n",
    "\n",
    "soup_data=soup(request,'html.parser')\n",
    "\n",
    "player_pos=[]\n",
    "player_name=[]\n",
    "player_nation=[]\n",
    "player_rating=[]\n",
    "\n",
    "info=soup_data.find_all('tr',attrs={'class':'rankings-block__banner'})\n",
    "\n",
    "for infor in info:\n",
    "    information=infor.find('td',class_='rankings-block__position').text\n",
    "    player_pos.append(information)\n",
    "    \n",
    "    information=infor.find('div',class_='rankings-block__banner--name-large').text\n",
    "    player_name.append(information)\n",
    "    \n",
    "    information=infor.find(class_='flag-15')\n",
    "    player_nation.append(str(information).split('\"')[1].split()[1])\n",
    "    \n",
    "    information=infor.find(class_='rankings-block__banner--rating').text\n",
    "    player_rating.append(information)\n",
    "    infos=soup_data.find_all('tr',attrs={'class':'table-body'})\n",
    "\n",
    "count=0\n",
    "\n",
    "for infor in infos:\n",
    "    count=count+1\n",
    "    information=infor.find('td',class_='table-body__cell table-body__cell--position u-text-right').text.strip()\n",
    "    player_pos.append(information)\n",
    "    \n",
    "    information=infor.find('td',class_='table-body__cell rankings-table__name name').text.strip()\n",
    "    player_name.append(information)\n",
    "    \n",
    "    information=infor.find('span',class_='table-body__logo-text').text\n",
    "    player_nation.append(information)\n",
    "    \n",
    "    information=infor.find('td',class_='table-body__cell rating').text\n",
    "    player_rating.append(information)\n",
    "    if count>8:\n",
    "        break\n",
    "\n",
    "for player_info in range(10):\n",
    "    print('Player Position :',player_pos[player_info],'\\nPlayer Name :',player_name[player_info],'\\nPlayer Nationality :',player_nation[player_info],'\\nPlayer Rating :',player_rating[player_info],'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605ce20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c)\n",
    "url=get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")\n",
    "\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "from requests import get\n",
    "request=url.text\n",
    "\n",
    "soup_data=soup(request,'html.parser')\n",
    "\n",
    "player_pos=[]\n",
    "player_name=[]\n",
    "player_nation=[]\n",
    "player_rating=[]\n",
    "\n",
    "info=soup_data.find_all('tr',attrs={'class':'rankings-block__banner'})\n",
    "\n",
    "for infor in info:\n",
    "    information=infor.find('td',class_='rankings-block__position').text\n",
    "    player_pos.append(information)\n",
    "    \n",
    "    information=infor.find('div',class_='rankings-block__banner--name-large').text\n",
    "    player_name.append(information)\n",
    "    \n",
    "    information=infor.find(class_='flag-15')\n",
    "    player_nation.append(str(information).split('\"')[1].split()[1])\n",
    "    \n",
    "    information=infor.find(class_='rankings-block__banner--rating').text\n",
    "    player_rating.append(information)\n",
    "\n",
    "infos=soup_data.find_all('tr',attrs={'class':'table-body'})\n",
    "\n",
    "count=0\n",
    "\n",
    "for infor in infos:\n",
    "    count=count+1\n",
    "    information=infor.find('td',class_='table-body__cell table-body__cell--position u-text-right').text.strip()\n",
    "    player_pos.append(information)\n",
    "    \n",
    "    information=infor.find('td',class_='table-body__cell rankings-table__name name').text.strip()\n",
    "    player_name.append(information)\n",
    "    \n",
    "    information=infor.find('span',class_='table-body__logo-text').text\n",
    "    player_nation.append(information)\n",
    "    \n",
    "    information=infor.find('td',class_='table-body__cell rating').text\n",
    "    player_rating.append(information)\n",
    "    if count>8:\n",
    "        break\n",
    "\n",
    "for player_info in range(10):\n",
    "    print('Player Position :',player_pos[player_info],'\\nPlayer Name :',player_name[player_info],'\\nPlayer Nationality :',player_nation[player_info],'\\nPlayer Rating :',player_rating[player_info],'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21009236",
   "metadata": {},
   "source": [
    "5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "ii) Top 10 women’s ODI players along with the records of their team and rating.\n",
    "iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20d9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sol 5.\n",
    "# a)\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "url=get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "team_ranking=[]\n",
    "team_name=[]\n",
    "team_match=[]\n",
    "team_point=[]\n",
    "team_rating=[]\n",
    "\n",
    "request=url.text\n",
    "\n",
    "soup_data=Soup(request,'html.parser')\n",
    "\n",
    "ranking=soup_data.find_all('tr',class_='rankings-block__banner')\n",
    "\n",
    "for rank in ranking:\n",
    "    team=rank.find('td',{'class':'rankings-block__banner--pos'}).text\n",
    "    team_ranking.append(team)\n",
    "    \n",
    "    team=rank.find('span',{'class':'u-hide-phablet'}).text\n",
    "    team_name.append(team)\n",
    "    \n",
    "    team=rank.find('td',{'class':'rankings-block__banner--matches'}).text\n",
    "    team_match.append(team)\n",
    "    \n",
    "    team=rank.find('td',{'class':'rankings-block__banner--points'}).text\n",
    "    team_point.append(team)\n",
    "    \n",
    "    team=rank.find('td',{'class':'rankings-block__banner--rating u-text-right'}).text.strip()\n",
    "    team_rating.append(team)\n",
    "\n",
    "rankings=soup_data.find_all('tr',class_='table-body')\n",
    "\n",
    "for rank in rankings:\n",
    "    team=rank.find('td',{'class':'table-body__cell table-body__cell--position u-text-right'}).text\n",
    "    team_ranking.append(team)\n",
    "    \n",
    "    team=rank.find('span',{'class':'u-hide-phablet'}).text\n",
    "    team_name.append(team)\n",
    "    \n",
    "    team=rank.find('td',{'class':'table-body__cell u-text-right rating'}).text\n",
    "    team_rating.append(team)\n",
    "    \n",
    "matchpoint=soup_data.find_all('td',class_='table-body__cell u-center-text')\n",
    "count=1\n",
    "for point in matchpoint:\n",
    "    if count%2!=0:\n",
    "        team_match.append(matchpoint[count-1].text)\n",
    "    else:\n",
    "        team_point.append(matchpoint[count-1].text)\n",
    "    count=count+1\n",
    "    if count>20:\n",
    "        break\n",
    "        \n",
    "\n",
    "for team_info in range(10):\n",
    "    print('Team Position :',team_ranking[team_info],'\\nTeam Nationality :',team_name[team_info],'\\nTeam Matches :',team_match[team_info],'\\nTeam Points :',team_point[team_info],'\\nTeam Rating :',team_rating[team_info],'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a82702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b)\n",
    "from requests import get\n",
    "\n",
    "url=get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/bowling\")\n",
    "\n",
    "\n",
    "request=url.text\n",
    "\n",
    "soup_data=soup(request,'html.parser')\n",
    "\n",
    "player_pos=[]\n",
    "player_name=[]\n",
    "player_nation=[]\n",
    "player_rating=[]\n",
    "\n",
    "info=soup_data.find_all('tr',attrs={'class':'rankings-block__banner'})\n",
    "\n",
    "for infor in info:\n",
    "    information=infor.find('td',class_='rankings-block__position').text\n",
    "    player_pos.append(information)\n",
    "    \n",
    "    information=infor.find('div',class_='rankings-block__banner--name-large').text\n",
    "    player_name.append(information)\n",
    "    \n",
    "    information=infor.find(class_='flag-15')\n",
    "    player_nation.append(str(information).split('\"')[1].split()[1])\n",
    "    \n",
    "    information=infor.find(class_='rankings-block__banner--rating').text\n",
    "    player_rating.append(information)\n",
    "\n",
    "infos=soup_data.find_all('tr',attrs={'class':'table-body'})\n",
    "\n",
    "count=0\n",
    "\n",
    "for infor in infos:\n",
    "    count=count+1\n",
    "    information=infor.find('td',class_='table-body__cell table-body__cell--position u-text-right').text.strip()\n",
    "    player_pos.append(information)\n",
    "    \n",
    "    information=infor.find('td',class_='table-body__cell rankings-table__name name').text.strip()\n",
    "    player_name.append(information)\n",
    "    \n",
    "    information=infor.find('span',class_='table-body__logo-text').text\n",
    "    player_nation.append(information)\n",
    "    \n",
    "    information=infor.find('td',class_='table-body__cell rating').text\n",
    "    player_rating.append(information)\n",
    "    if count>8:\n",
    "        break\n",
    "\n",
    "for player_info in range(10):\n",
    "    print('Player Position :',player_pos[player_info],'\\nPlayer Name :',player_name[player_info],'\\nPlayer Nationality :',player_nation[player_info],'\\nPlayer Rating :',player_rating[player_info],'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2710d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c)\n",
    "from requests import get\n",
    "\n",
    "url=get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")\n",
    "request=url.text\n",
    "\n",
    "soup_data=soup(request,'html.parser')\n",
    "\n",
    "player_pos=[]\n",
    "player_name=[]\n",
    "player_nation=[]\n",
    "player_rating=[]\n",
    "\n",
    "info=soup_data.find_all('tr',attrs={'class':'rankings-block__banner'})\n",
    "\n",
    "for infor in info:\n",
    "    information=infor.find('td',class_='rankings-block__position').text\n",
    "    player_pos.append(information)\n",
    "    \n",
    "    information=infor.find('div',class_='rankings-block__banner--name-large').text\n",
    "    player_name.append(information)\n",
    "    \n",
    "    information=infor.find(class_='flag-15')\n",
    "    player_nation.append(str(information).split('\"')[1].split()[1])\n",
    "    \n",
    "    information=infor.find(class_='rankings-block__banner--rating').text\n",
    "    player_rating.append(information)\n",
    "\n",
    "infos=soup_data.find_all('tr',attrs={'class':'table-body'})\n",
    "\n",
    "count=0\n",
    "for infor in infos:\n",
    "    count=count+1\n",
    "    information=infor.find('td',class_='table-body__cell table-body__cell--position u-text-right').text.strip()\n",
    "    player_pos.append(information)\n",
    "    \n",
    "    information=infor.find('td',class_='table-body__cell rankings-table__name name').text.strip()\n",
    "    player_name.append(information)\n",
    "    \n",
    "    information=infor.find('span',class_='table-body__logo-text').text\n",
    "    player_nation.append(information)\n",
    "    \n",
    "    information=infor.find('td',class_='table-body__cell rating').text\n",
    "    player_rating.append(information)\n",
    "    if count>8:\n",
    "        break\n",
    "\n",
    "for player_info in range(10):\n",
    "    print('Player Position :',player_pos[player_info],'\\nPlayer Name :',player_name[player_info],'\\nPlayer Nationality :',player_nation[player_info],'\\nPlayer Rating :',player_rating[player_info],'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed5b618",
   "metadata": {},
   "source": [
    "6. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbc814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sol 6. Due to 503 error the data cant be scraped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a29be44",
   "metadata": {},
   "source": [
    "7. Write a python program to scrape house details from mentioned url. It should include house title, location, area, emi and price\n",
    "\"https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44N DUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8 iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be50b9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sol 7.\n",
    "url = 'https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44N DUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8 iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser') \n",
    "broker_info = soup.find_all ('div', {'class' : 'nb__2JHKO'})\n",
    "\n",
    "house_name=[]\n",
    "for i in broker_info:\n",
    "    restro = i.find('section', class_ ='nb__37AJO').text.split(',')[0]\n",
    "    house_name.append(restro)\n",
    "    \n",
    "location=[]\n",
    "for j in broker_info:\n",
    "    loc = j.find('div', class_ ='nb__sDz3z').text.split(',')[1:]\n",
    "    location.append(loc)\n",
    "    \n",
    "area=[]\n",
    "for k in broker_info:\n",
    "    a = k.find('div', class_ ='nb__3oNyC').text\n",
    "    area.append(a)\n",
    "\n",
    "#informations=[]\n",
    "emi=[]\n",
    "for v in broker_info:\n",
    "    b = v.find('div', class_ ='font-semi-bold heading-6').text\n",
    "    area.append(b)\n",
    "house_dF = pd.DataFrame({'House Name' : house_name, \"Location\" : location, \"Area\" : area, \"EMI\" : emi })\n",
    "house_dF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb79ae",
   "metadata": {},
   "source": [
    "8. Write a python program to scrape mentioned details from ‘https://www.dineout.co.in/delhi-restaurants/buffet-special’ :\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48dbf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sol 8.\n",
    "url = 'https://www.dineout.co.in/delhi-restaurants/buffet-special'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "restaurant_info = soup.find_all ('div', {'class' : 'restnt-card restaurant'})\n",
    "\n",
    "#i) \n",
    "restro_name = []  \n",
    "for stuny in restaurant_info:\n",
    "    restro = stuny.find('div', class_ ='restnt-info cursor').text.split(',')[0]\n",
    "    restro_name.append(restro)\n",
    "\n",
    "#ii)\n",
    "cuisine = []  \n",
    "for stuny in restaurant_info:\n",
    "    cuisine_n = stuny.find('span', class_ ='double-line-ellipsis').text.split('|')[1]\n",
    "    cuisine.append(cuisine_n)\n",
    "\n",
    "#iii)\n",
    "locations = []  \n",
    "for stuny in restaurant_info:\n",
    "    locs_data = stuny.find('div', class_ ='restnt-loc ellipsis').text    \n",
    "    locations.append(locs_data)   \n",
    "\n",
    "#iv)\n",
    "ratings = []  \n",
    "for stuny in restaurant_info:\n",
    "    ratings_data = stuny.find('div', class_ ='img-wrap').text    \n",
    "    ratings.append(ratings_data)\n",
    "    \n",
    "#v)\n",
    "Image_url = []  \n",
    "for stuny in restaurant_info:\n",
    "    img_data = stuny.find('img', class_ ='no-img')\n",
    "    Image_url.append(img_data['data-src']) \n",
    "\n",
    "restro_dF = pd.DataFrame({'Restaurant Name' : restro_name, \"Cuisine\" : cuisine, \"Location\" : locations, \"Ratings\" : ratings , \"Image URL\" : Image_url})\n",
    "restro_dF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee01341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbd3f43e",
   "metadata": {},
   "source": [
    "9. Write a python program to scrape weather details for last 24 hours from ‘https://en.tutiempo.net/delhi.html?data=last-24- hours’ :\n",
    "i) Hour\n",
    "ii) Temperature\n",
    "iii) Wind\n",
    "iv) Weather condition\n",
    "v) Humidity\n",
    "vi) Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c61a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sol 9.\n",
    "url = \"https://en.tutiempo.net/delhi.html?data=last-24-hours\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "hour=[]\n",
    "for i in soup.find_all('td',class_='t Temp')[0:24]:\n",
    "    if i.previous_sibling.previous_sibling is not None:\n",
    "          hour.append(i.previous_sibling.previous_sibling.text)\n",
    "    else:\n",
    "        Hour.append(' ')\n",
    "temp=[]\n",
    "for j in soup.find_all('td',class_='t Temp'):\n",
    "    tempt=j.text\n",
    "    temp.append(tempt)\n",
    "\n",
    "wind=[]\n",
    "for k in soup.find_all('td',class_='wind'):\n",
    "    w=k.text\n",
    "    wind.append(w)\n",
    "    \n",
    "weather_cond=[]\n",
    "for l in soup.find_all('span',class_='thhip ico i0530 u303n'):\n",
    "    x=l.text\n",
    "    weather_cond.append(x)\n",
    "        \n",
    "humidity=[]\n",
    "for n in soup.find_all('td',class_='hr'):\n",
    "    y=n.text\n",
    "    humidity.append(y)\n",
    "    \n",
    "pressure =[]\n",
    "for p in soup.find_all('td',class_='prob'):\n",
    "    ze= p.text\n",
    "    pressure.append(ze)\n",
    "\n",
    "climate_dF=pd.DataFrame({'Hour' : hour, 'Temperature' : temp, 'Wind' : wind, 'Weather Condition' : weather_cond , 'Humidity' : humidity, 'Pressure' : pressure})\n",
    "climate_dF "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98acd168",
   "metadata": {},
   "source": [
    "10. Write a python program to scrape monument name, monument description, image url about top 10 monuments from 'https://www.puredestinations.co.uk/top-10-famous-monuments-to-visit-in-india/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c3a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sol 10.\n",
    "url = \"https://www.puredestinations.co.uk/top-10-famous-monuments-to-visit-in-india/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "table= soup.find_all('div', class_ ='blog--single__content column--3-4 u-spacing-third')\n",
    "place=[]\n",
    "for i in table:\n",
    "    for j in i.find_all('p'):\n",
    "        t= j.text.replace('\\n','')\n",
    "        place.append(t)\n",
    "        \n",
    "name= []\n",
    "desc = []\n",
    "for i in range(1,30,3):\n",
    "    name.append(place[i])\n",
    "for i in range(2,30,3):\n",
    "    desc.append(place[i])\n",
    "\n",
    "temp =[]\n",
    "for t in soup.find_all('img'):\n",
    "    temp.append(t['src'])\n",
    "img_url=[]\n",
    "for t in range(6,26,2):\n",
    "    img_url.append(temp[t])\n",
    "    \n",
    "monument_dF = pd.DataFrame({'Monument Name' : name, \"Monument Description\" : desc, \"Image URL\" : img_url})\n",
    "monument_dF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8041fdca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7911fca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
